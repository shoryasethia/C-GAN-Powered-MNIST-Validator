{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Similarity Index Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,_),(X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator = models.load_model('generator-mnist-cgan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(y_test)\n",
    "num_labels = 10\n",
    "noise_dim = 100\n",
    "\n",
    "noises = tf.random.normal([num_samples, noise_dim])\n",
    "\n",
    "label = y_test\n",
    "label = tf.convert_to_tensor(label, dtype=tf.int32)\n",
    "\n",
    "generated_imgs = generator([noises, label], training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def compute_average_ssim(real_images, generated_images, win_size=3):\n",
    "    \"\"\"\n",
    "    Compute the average SSIM for a list of real and generated images.\n",
    "\n",
    "    Args:\n",
    "    - real_images (ndarray): Array of real images. Shape should be (num_images, height, width, channels).\n",
    "    - generated_images (ndarray): Array of generated images. Shape should be (num_images, height, width, channels).\n",
    "    - win_size (int): The size of the sliding window for SSIM computation.\n",
    "\n",
    "    Returns:\n",
    "    - float: The average SSIM value.\n",
    "    \"\"\"\n",
    "    ssim_values = []\n",
    "    counter = 1\n",
    "    \n",
    "    for real, generated in zip(real_images, generated_images):\n",
    "        # Ensure images are at least 7x7\n",
    "        if real.shape[0] < win_size or real.shape[1] < win_size:\n",
    "            raise ValueError(\"Image dimensions are smaller than win_size.\")\n",
    "        \n",
    "       # Convert images to numpy array and squeeze if necessary\n",
    "        if isinstance(real, tf.Tensor):\n",
    "            real = np.array(real)\n",
    "        if isinstance(generated, tf.Tensor):\n",
    "            generated = np.array(generated)\n",
    "            \n",
    "        real = np.squeeze(real, axis=-1)  # Remove single-channel dimension if present\n",
    "        generated = np.squeeze(generated, axis=-1)\n",
    "        \n",
    "        # Compute SSIM\n",
    "        ssim_value = ssim(real, generated, win_size=win_size, data_range=generated.max() - generated.min())\n",
    "        ssim_values.append(ssim_value)\n",
    "        counter += 1\n",
    "        if(counter%200==0) :\n",
    "            print(f\"similarity caculated for {counter} images\")\n",
    "    \n",
    "    return np.mean(ssim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are supposed to be in the range [0, 1]\n",
    "real_images = X_test \n",
    "generated_images = generated_imgs * 127.5 + 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = real_images.reshape(real_images.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity caculated for 200 images\n",
      "similarity caculated for 400 images\n",
      "similarity caculated for 600 images\n",
      "similarity caculated for 800 images\n",
      "similarity caculated for 1000 images\n",
      "similarity caculated for 1200 images\n",
      "similarity caculated for 1400 images\n",
      "similarity caculated for 1600 images\n",
      "similarity caculated for 1800 images\n",
      "similarity caculated for 2000 images\n",
      "similarity caculated for 2200 images\n",
      "similarity caculated for 2400 images\n",
      "similarity caculated for 2600 images\n",
      "similarity caculated for 2800 images\n",
      "similarity caculated for 3000 images\n",
      "similarity caculated for 3200 images\n",
      "similarity caculated for 3400 images\n",
      "similarity caculated for 3600 images\n",
      "similarity caculated for 3800 images\n",
      "similarity caculated for 4000 images\n",
      "similarity caculated for 4200 images\n",
      "similarity caculated for 4400 images\n",
      "similarity caculated for 4600 images\n",
      "similarity caculated for 4800 images\n",
      "similarity caculated for 5000 images\n",
      "similarity caculated for 5200 images\n",
      "similarity caculated for 5400 images\n",
      "similarity caculated for 5600 images\n",
      "similarity caculated for 5800 images\n",
      "similarity caculated for 6000 images\n",
      "similarity caculated for 6200 images\n",
      "similarity caculated for 6400 images\n",
      "similarity caculated for 6600 images\n",
      "similarity caculated for 6800 images\n",
      "similarity caculated for 7000 images\n",
      "similarity caculated for 7200 images\n",
      "similarity caculated for 7400 images\n",
      "similarity caculated for 7600 images\n",
      "similarity caculated for 7800 images\n",
      "similarity caculated for 8000 images\n",
      "similarity caculated for 8200 images\n",
      "similarity caculated for 8400 images\n",
      "similarity caculated for 8600 images\n",
      "similarity caculated for 8800 images\n",
      "similarity caculated for 9000 images\n",
      "similarity caculated for 9200 images\n",
      "similarity caculated for 9400 images\n",
      "similarity caculated for 9600 images\n",
      "similarity caculated for 9800 images\n",
      "similarity caculated for 10000 images\n",
      "Average SSIM: 0.6188459675449165\n"
     ]
    }
   ],
   "source": [
    "average_ssim = compute_average_ssim(real_images, generated_images)\n",
    "print(f'Average SSIM: {average_ssim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6188 is moderately good score.\n",
    "## Score ranges from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
